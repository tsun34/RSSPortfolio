Lab 3
=====

## Overview and Motivations - Michelle

This lab was our first opportunity to implement basic software control on the physical racecar instead of just in simulation. The first pieces of software that we needed to write were a wall follower and a safety controller. The wall follower was an opportunity to test out a simple closed-loop control model where we incorporated information from the sensors in order to control the robot through an environment. The safety controller was an essential piece of software that will run in the background of all future nodes we write, acting as a last resort program that prevents us from crashing into obstacles. We knew that making a robust, but not overly-cautious controller would be beneficial to us in future labs.

In this lab, we also were able to work with our teams for the first time. In the past, our labs were mostly individual. Working in teams made it easier to generate ideas, but also posed some new challenges. We had to figure out how to split up the work efficiently and utilize the strengths of each team member. In addition, being able to work on different things in parallel allowed us to have the ability to get more done, but also made the communication a lot more complicated. Working effectively with our teams this semester will be crucial to the success of our team this semester.

## Proposed Approach - Fredric

Our approach will be to monitor the current state of the robot, and respond if we sense a possible imminent crash. Specifically, we subscribe to laser scan data and the navigation commands published to the robot, to understand the robot's surroundings and intentions. The safety controller is a failsafe against crashes and will only come into effect to completely stop the vehicle to prevent collisions. This safety controller will be used for any type of collision; with stationary and dynamic obstacles alike.

### Initial Setup - Fredric

In order to version control all of our code, we set up an organization on Github to help organize our software. In order to allow an ssh connection to the robot, we established public key encryption between the robot and repository. This lets us pull software down onto the robot without ever having to develop while ssh’ed onto the robot’s machine.

Our workflow will involve creating branches off master and then submitting pull requests once the code is fully functioning. For now, we will have another team member merge the pull request and check that the code is indeed functioning. Since we all have VMs, we can individually simulate our branch’s code in the first instance to see validate it.

For now, we will individually name our branch’s by our name to make it easy to find code that a specific person is writing. We may change this flow as we end up implementing more complex features in parallel, but is helpful and efficient for now.

We created a lab3 repository which contains two packages, the wall follower and safety controller. In order to test the safety controller, we also created a Driver Test Node Package which is in a separate repository as it may be useful in future labs. This lets us set the robot's speed and direction by publishing to the lowest priority mux.

This is true because we want to control the robot (choose velocity and directions) such that we can test the safety controller. We can not test the safety controller with the teleop joystick since its priority in the mux chart is higher than the safety controller.



### Technical Approach - Josh and Victor

Lab3 consists of two main pieces of software, the Wall Follower, and the Safety Controller.

The Wall Follower controls the main function of the racecar in this week’s lab, which is to drive at a constant speed parallel to a wall while attempting to stay as close as possible to an exact desired distance from the wall at all times. To accomplish this, our team built a PD controller, which means that the steering angle of our car was determined by a proportional term and a derivative term. The proportional term is the proportion of the car’s actual distance to the wall to the desired distance to the wall. If the car is farther from the wall than desired, the car’s steering angle is adjusted to drive towards the wall, and if the car is closer to the wall than desired the car will adjust in the opposite direction to drive away from the wall. The derivative term is the velocity of our car relative to the wall, meaning how fast we are changing our distance from the wall. If our car is at the exact desired distance from the wall, we would want this term to be 0, since we do not want the car to change its distance from the wall. If our term is positive this means our car is angled to drive closer to the wall, and if it is negative the car is angled to drive away from the wall. If we are driving at too sharp of an angle towards or away from the wall, the derivative term will counteract this and change our steering angle to drive parallel to the wall. Our derivative term works alongside our proportional term to not only keep the car at the correct distance from the wall, but to keep it headed in the correct direction at all times.

While this method works very well in practice, both on a real car and in a simulator, it could be optimized with a Integral term to create a PID controller. The integral term keeps track of the previous distances from the wall, and could help in smoothing out the path of the car and keeping it more consistent.

The Wall Follower was originally built by each member of the team separately in the previous week, and tested on a simulator. This week we combined the best parts of each of our individual projects to create the ideal PD controller for a physical robot.

To implement the Safety Controller, we needed the car to stop if any objects were directly in its path.  Avoiding such collisions required us to look at laser scan data from our LIDAR sensor.  We had to take a section of the laser scan data that looked forward for objects in our path and flag objects that were within a certain distance.  At first we used a fixed stopping time and a fixed angle view width to look for obstacles.  This means we stopped the car if any object within the lookahead view was a small enough distance from the car that we would hit it within the fixed stopping time.  ￼￼

![](assets/images/lab3/view_range_diagram.png)
![](assets/images/lab3/view_range_turning.png)

We quickly noticed a few flaws in this plan.  First, when the car moved quickly, our lookahead view was flagging objects way off to the sides.  This is because the size of the area we were checking was growing as velocity increased.  We realized we needed to decrease the angle view width as speed increased so we were only looking for objects directly in the path of the car.  We calculated this angle by measuring the width of the car and taking the inverse tangent of the width divided by the velocity.  This checked a smaller range of angles as we sped up so the car only stopped if something was directly in its path.  As the diagram in Image 1 shows, as the speed increased, the distance we had to check for objects increased from d1 to d2.  This corresponded to a decrease in the angle we had to check from theta1 to theta2.￼

The second problem we encountered with our initial simplistic approach was the fixed stopping time.  We noticed that driving the car at faster speeds caused the car to stop well short of obstacles.  We came to the realization that rather than setting a stopping time, we should set a stopping distance based on the velocity.  Rather than checking for objects we would collide with within a certain time, we decided to check for objects within a certain distance that depended on the velocity of the car.  We included an offset to account for the distance between the sensor and the front of the car, and we tuned a parameter through testing on the physical car that we multiplied by the velocity and added to the offset.  

We also considered how to deal with a turning car.  We decided to approximate the path of the car using the steering angle of the wheels.  For small distances, the car travels in approximately a straight line in the direction of the angle of the wheels.  Using this estimate, we adjust the angles that we look at in the laser scan data to check for objects in the approximate path.  We recognize the shortcomings of this approximation: the car travels in a circle instead of a straight line when the wheels are turned so some objects might not be flagged, and the front of the car can still run into objects if the car is placed in certain orientations near an object.  However, we found in testing that such problematic situations only arose in highly contrived scenarios.  We plan on improving the Safety Controller in future weeks to fix these edge cases.


### ROS Implementation - Fredric

As our ROS project grows, we want to modularize each part of a package as much as possible. Following the ROS guidelines, we have created parameter files for each package. These files are compiled in the launch file to automate our bootstrapping process.

## Experimental Evaluation - Victor

The Wall Follower was originally tested as an individual project for each member. Each member of the team built an implementation of the wall follower and tested it using staff written tests in a simulator. Once we were organized into our team, these test simulations helped us understand the pros and cons of each members implementation, and allowed us to combine our previous efforts to build our initial team implementation of Wall Follower.

### Testing Procedure and Results - Josh, Victor, and Michelle

The Wall Follower initially worked fairly well on the robot.  We tested the car in several starting orientations: facing the wall, facing away from the wall, facing parallel to the wall.  We also tested the car at varying speeds and with various desired distances to the wall.  During these tests, we realized that our car was having trouble making tight turns at high speeds.  Since our individual simulated wall follower had only been tested at a single speed, our Wall Follower did not initially perform well at high speeds.  However, small tweaks to our derivative term allowed the car to avoid crashing into corners and follow the wall relatively consistently.  The Wall Follower even succeeded in tests we ran where the wall it was following had indentations.  Once the wall follower worked well enough it was on to implementing and testing the safety controller.

We tested our Safety Controller by placing the robot in various situations with obstacles in different locations.  We initially tested the Safety Controller by running the Wall Follower code with the Safety Controller on top of it and ensuring that the car did not crash into any obstacles.  We first just had the car drive directly at a wall and not attempt to turn to see if the car stopped before the wall.  During this first simple test, we found that the car was inching forward intermittently after detecting the wall and stopping.  Soon afterwards, we realized this was because we were publishing to the wrong drive topic.  Instead of our Safety Controller commands overriding autonomous driving commands, they were published at the same priority level so the car was sometimes executing the autonomous commands.  Once we fixed this minor bug, our basic implementation worked well.

We then moved on to placing objects in the way of the car.  We placed as well as threw objects in front of the car to test its robustness to the movement of obstacles.  It performed adequately in both situations.  We also tested the car at different speeds and with objects near the path and in the path.  These tests revealed the issues discussed in the Technical Approach section for the Safety Controller.  Ultimately, these tests led us to vary our two parameters, the distance at which we flagged objects and the range of angles which we checked for objects, based on the speed of the car.  The exact parameters still need some fine-tuning, but our Safety Controller works to the point that most objects outside of the path while be ignored while objects that the car would otherwise run into trigger an override that stops the car.


![alt text](https://media.giphy.com/media/1lwtoO27B0kQMausv3/giphy.gif)

The final piece of testing we did was placing obstacles in the way of the car as it turned.  As discussed in the Technical Approach section, approximating the arcing path of the car as a straight line for collision detection worked adequately for our purposes.  When objects were placed off to the side of the car and the car tried to turn into them, the Safety Controller took over and stopped the car.  One edge case we worked on fixing was the case where the car is turning and something is placed directly in front of it.  We are working on developing strategies to only stop the car if a collision is imminent with this object but to allow the car to continue if, by turning, it will avoid this object.  We noticed another peculiar edge case during our testing.  For thin objects, such as chair legs, the car stopped too late to avoid crashing into the object.  We hypothesize that for sufficiently thin objects, there are very few, if any, laser points that hit the object, resulting in potentially inaccurate data.  While we plan to do further testing in future labs, this may just be an inherent limitation of the system on which we will have to work to minimize the negative effects.

 We tested that our initial implementation worked by driving the simulated racecar into walls and checking that it was both stopping and checking the right laser scans. We added markers that showed which laser scan points the robot was looking at to detect possible obstacles. This saved a lot of time with debugging in real life and minimized the risks of damage to the car caused by running malfunctional safety controllers.

## Lessons Learned - Michelle

On the communication aspects of the project, it was also important to spend time planning the ground rules for how we were going to collaborate effectively before starting. We faced some challenges with our workflow and communication, which we fixed by trial and error as we progressed. One of the first things we had to deal with was making sure that we could all work on the same program while not hindering each others progress. We figured out that it would be best if we all made different branches and merged them together as we went along. In addition, we should have explicitly delegated tasks at the beginning. Since this was the first lab, it was hard to do this because we were unclear on the scope of the lab and of the strengths of each member of the team. As a result, it was really hard to keep track of what everyone was working on and we were definitely slowed down by not having everyone always on the same page. As we went on, we established as team that we were going to write code that was easy to understand, so that it would be clear just by looking at the code what the program was calculating.

### Technical Conclusions - Michelle

On both the technical and collaborative aspects of the lab, there was a common theme of the importance of planning. On the technical side, it was important to plan before starting to implement. Our team would have done a lot better if we had spent more time at the beginning thinking about how our proposed strategy would deal with all edge cases. Our initial idea for the safety controller was to have it stop at a fixed time before a collision would occur. Although this made sense in theory, when we implemented it and tested it, we realized that with this approach, the racecar would stop really far away from the wall if it were going at a faster velocity. This seemed really unintuitive to us, but the racecar was implementing the strategy correctly. In the racecar’s perspective, it stops early because it realizes that if it were to continue with the current velocity, it could potentially hit the wall. After going through the work of implementing this, we realized that what we actually wanted was for the safety controller to cause the robot to stop at a fixed distance from the wall no matter what the velocity was previously. In addition, when processing the scans, our initial idea was to only look in the direction that the wheels were generally turning. Although it made sense generally, we never accounted for the test cases where something was in front of the robot, but the wheels were turned away from the object. In general, we should have put more emphasis on making sure that everyone understood and agreed with any code that was being put on the robot. Just by talking through the algorithms a little bit more, we could have caught a lot of implementation bugs.

### CI Conclusions - All members

1. Victor Fink - Our team communicated effectively with two forms of communication, Faceboook messenger and Slack. We used Facebook to comunicate about when to meet up, how we were going to split up responsibilities. We used Slack to communicate about technical problems and solutions. This was a good process for splitting up communication and we we use it in the same way in the future.
2. Josh Rosenkranz- Throughout this lab, our team learned the importance of unambiguous communication.  Whenever we didn't set clear expectations of what each person had to do, the work rarely got done.  On the contrary, whenever we gave each other explicit tasks, our team members were enthusiastic and got the work done on time.
3. Michelle Tan- Although we didn't explicitly split up the work, we were still able to get the job done in the end. We learned that we can get a lot farther when we are all on the same page. I think with a 5th person, it would have been a less overwhelming amount of work.
4. Fredric Moezinia - We have a great team dynamic, however, the complex nature of the tasks and robot environment caused a lot of overhead. Hopefully this is a function of the fact that this was our first group assignment. I'm sure that our synergies will lead to more efficient and great accomplishments in tasks to come.
